# multimodality_review
BLIP vs LLaVA
## Краткое резюме

BLIP и LLaVA-1.5 
BLIP оптимизирована для классических задач подписи к изображениям и простой VQA: у неё достаточно высокие метрики точности на COCO.
LLaVA-1.5 объединение декодора и визуального энкодера, что позволяет ей вести диалог, распознавать текст на картинках и решать сложные задачи с рассуждением. 

---

## Архитектура моделей

### BLIP  
- Энкодер–декодер на базе ViT и общего трансформера  
- Vision Transformer кодирует изображение  
- Трансформер с шарингом параметров обрабатывает и генерирует текст  
- Поддерживает и понимание «картинка–текст», и авторегрессионное генерирование подписей

### LLaVA-1.5  
- Визуальный энкодер (CLIP-ViT) + языковая модель (Vicuna/LLaMA)  
- Простой MLP-слой между ними для конвертации визуальных признаков  
- Схема работы: картинка → признаки → проекция → генерация через LLM

---

## Решаемые задачи

- **BLIP**  
  - Image Captioning  
  - Visual Question Answering (VQA)  
  - Retrieval (поиск совпадений «картинка–текст»)

- **LLaVA-1.5**  
  - Подробные описания сцен  
  - Диалоговый VQA, включая OCR  
  - Сложные рассуждения и multi-turn инструкции

---

## Обучающие данные

- **BLIP**  
  - COCO, Visual Genome, SBU, Conceptual Captions  
  - Крупный веб-корпус LAION для «bootstrapping captions»

- **LLaVA-1.5**  
  - Синтетические подписи от BLIP + реальные пары «картинка–текст»  
  - ≈158 K инструкций от GPT-4  
  - ≈450 K академических VQA-примеров и диалоги из ShareGPT

---

## Область применения

- **BLIP**  
  - Быстрая генерация точных подписей  
  - Простые VQA-системы  
  - Интеграция в пайплайны с ограниченными ресурсами

- **LLaVA-1.5**  
  - Мультимодальные чат-боты  
  - Научные QA и TextVQA  
  - OCR-задачи и сложные визуальные рассуждения

---

## Универсальность

- **BLIP**  
  - Широко покрывает классические VL-задачи, но без диалога  
  - «Один запрос - один ответ»

- **LLaVA-1.5**  
  - Гибко обрабатывает любые инструкции и историю диалога  
  - Требует больше вычислительных ресурсов

---

## Результаты и сравнение качества

## A. Сравнение общего качества

**BLIP**  
- Превосходит LLaVA-1.5 в Captioning — генерирует более точные, релевантные и лаконичные подписи.  
- В VQA на стандартных бенчмарках (VQAv2) часто достигает более высокой точности при простых вопросах.

**LLaVA-1.5**  
- Лучше справляется с задачами, требующими рассуждений, интерактивности и обобщения знаний.  
- Преимущество в сценариях сложного диалога и нетривиальных визуальных запросах.

---

## B. «Черри-пики»: когда одна модель лучше другой

### 1. Сценарии, где BLIP сильнее

**Captioning**  
- *Сцена:* на кухонном столе разложены нож, помидор и зелёный перец.  
- **BLIP:** “A knife next to sliced tomatoes and a green bell pepper on a wooden table.”  
- **LLaVA-1.5:** “Some vegetables on a table.”

**VQA**  
- *Вопрос:* “How many bananas are in the basket?”  
- **BLIP:** “Three.”  
- **LLaVA-1.5:** “It looks like a few bananas.”

---

### 2. Сценарии, где LLaVA-1.5 сильнее

**Рассуждение**  
- *Сцена:* дети играют в футбол, вокруг закатное солнце.  
- *Вопрос:* “Is this scene likely in the morning or evening?”  
- **LLaVA-1.5:** “Судя по оранжевому небу и длинным теням, это должно быть вечером.”  
- **BLIP:** не даёт развёрнутого ответа.

**Креатив**  
- *Задача:* “Write a short poem inspired by this image.”  
- **LLaVA-1.5:**  
  > “На зелёном поле мяч летит,  
  > Смеются дети — смех вдалеке звенит.  
  > Закат заливает мир теплом,  
  > Новых игр предвкушая взлёт.”  
- **BLIP:** ограничивается простой подписью: “Children playing soccer on a grassy field.”

---

## Итоговые выводы

1. **BLIP** — оптимальный выбор для классических Captioning/VQA-систем с упором на точность и эффективность.  
2. **LLaVA-1.5** — лучший вариант для интерактивных приложений, задач с рассуждениями, OCR и креативного контента.  
3. Оба подхода дополняют друг друга: BLIP — «рабочая лошадка» по метрикам, LLaVA — гибкий визуальный ассистент.

